### AML subchallenge 3 #############################################################################
# SCRIPT NAME
# ===========
#   chipmunks_aml_q3.R
#
# PACKAGE REQUIRED
# ================
#   survival, foreach, parallel, doMC, getopt
#
# MODEL SUMMARY
# =============
#   use the 5 selected covariates in AML benchmark model
#   re-categorize covariate `cyto.cat`
#   used `bagged cox` to reduce variation
#   use `oob` as performance estimate from training
#
# USAGE
# =====
#   For Unix-like system (tested) or Windows (not tested) run the following commands on the terminal:
#   cd DIRECTORY_CONTAIN_THIS_SCRIPT
#   Rscript --no-save --no-restore chipmunks_aml_q3.R -t PATH_TO_TRAINING_SET -s PATH_TO_TEST_SET -o DIRECTORY_TO_SAVE_OUTPUT
#   If in any case you don't have the `Rscript` command, you can run the following alternative command
#   R CMD BATCH --no-save --no-restore '--args -t PATH_TO_TRAINING_SET -s PATH_TO_TEST_SET -o DIRECTORY_TO_SAVE_OUTPUT' chipmunks_aml_q3.R
#
# INPUT/command line argument
# ===========================
#   --train  / -t (required) : path to the `csv` training data set (filename!)
#   --test   / -s (required) : path to the `csv` testing  data set (filename!)
#   --output / -o (optional) : an output `directory`(NOT filename!). Default to the current working directory 
#
# OUTPUT
# ======
#   two files (predictions on traning (using out-of-bag samples) and testing data set are generated and saved in the provideded 
#       directory specified by output argument ('--output / -o'), with names:
#       Chipmunks-AML_subchallenge3_submission_train.csv
#       Chipmunks-AML_subchallenge3_submission_test.csv
 
 
 
### load packages ##################################################################################
# make sure that these are installed !!!
library(survival);
library(foreach);
library(getopt);
library(parallel)
library(doMC);
registerDoMC(cores = detectCores());


### settings #######################################################################################
# get option from command line                                                                                                                                               
params <- matrix(
    c(
        'train', 't', 1, 'character',
		'test' , 's', 1, 'character',
		'output', 'o', 2, 'character'
        ),
    ncol = 4,
    byrow = TRUE
    );

if (!interactive())  opt <- getopt(params);

## if NOT run from terminal / command line, these 3 file paths must be provided.
path.train.data <- opt$train;
path.test.data  <- opt$test;
path.output     <- if(is.null(opt$output)) '.' else opt$output;
RANDOM_SEED <- 987;
set.seed(RANDOM_SEED);

### DEFINE AXILIARY FUNCTIONS ######################################################################

### get.pcc.ci ###
# DESCRIPTION:
#   Compute Pearson correlation coefficients(PCC) and concordance index(CI) of survival model.
# INPUT:
#   prediction: predicted survival time.
#   observed.time: observed survival time.
#   is.observed:  vector of 0/1 indication if observed.
# OUTPUT:
#   A vector containing PCC and CI.

get.pcc.ci <- function(prediction, observed.time, is.observed) {
	N <- length(observed.time);
	# sort the observed time ascendingly
	order.observed <- order(observed.time);
	observed.time <- observed.time[order.observed];
	prediction <- prediction[order.observed];
	is.observed <- as.logical(is.observed[order.observed]);
	# only the upper triangle part is assigned
	out.mat <- outer(1:N, 1:N, function(i, j) {
					 ifelse(
							(observed.time[i] < observed.time[j] & is.observed[i]) |
							(is.observed[i] & is.observed[j]),
							1,  NA
							)
	});
	is.concordance <- sign(outer(prediction, prediction, '-')) == sign(outer(observed.time, observed.time, '-'));
	return(
		   c(
			 'PCC' = ifelse(
							sum(is.observed) < 2,
							NA,
							(cor(prediction[is.observed], observed.time[is.observed], method = 'pearson') + 1 ) / 2
							),
			 'CI' = mean(out.mat*is.concordance, na.rm = TRUE)
			 )
		   );
}

### predictSurvival ###
# DESCRIPTION
#   Predict survival times givin percentile(p). Mainly for getting survival time after shrinkage methods
#       like `glmnet`, or gradient descent boosting and etc.
# INPUT
#   p            : a vector of percentile ranging from 0 to 1. If null, a step function returned.
#   test.link    : a vector of link (X %*% hat.beta, linear combination of covariates using predicted parameters)
#                : of the test data.  This is usually the outcome of `predict(..., type = 'link')`.
#   train.link   : a vector of link (X %*% hat.beta) of the training data, usually the outcome of `predict(..., type = 'link')`.
#   train.surv   : a vector of survival object generated by `Surv(time, status)`.
#                : If specified, train.time and train.status will be ignored.
#   train.time   : a vector of survival times of the training data.
#   train.status : a vector of survival status(whether it is an event) of the training data.
#   max.time     : the maximum observation time. It is used as the maximum predicted survival time.
#                : The default value here is 600 for the AML challenge.  Inf value is suported.
# OUTPUT
#   If `p` is specified, it returns a  matrix of surival time, with nrow = nrow(x) (sample size), ncol = length(p). 
#   If `p = NULL` (default), it return a stepped function for the baseline survival.
#       This function is an average of right/left-continuous version of survival function.

predictSurvival <- function(
							p = NULL,
							test.link = train.link,
							train.link,
							train.surv = Surv(train.time, train.status),
							train.time, train.status,
							max.time = 600
							) {
	if (missing(train.surv))
		train.surv <- Surv(train.time, train.status);
	if (nrow(train.surv) != length(train.link))
		stop('Sample sizes of input arguements do not match!');
	fit <- survfit(coxph(train.surv ~ offset(train.link), method = 'breslow'));
	time.base <- c(0, fit$time, max.time);
	surv.base <- c(1, fit$surv ^ exp(-mean(train.link)), 0); # baseline survival
	if (!is.null(p)) {
		# math:  S = S0*exp(eta). To solve S = p <=>  S0^exp(eta) = p => S0 = exp(log(p)/exp(eta)) =: p.S0
		p.S0 <- outer(test.link, p, function(link, prob) exp(log(prob) / exp(link)));
		# the first time which gives surv.base < p.S0 is the quantile wanted 
		out <- apply(p.S0, c(1, 2), function(x) time.base[surv.base <= x][1]);
		colnames(out) <- paste0('p=', p);
	}
	if (is.null(p)) {
		out <- function(t) {
			0.5 * stepfun(time.base, c(1, surv.base), right = FALSE)(t) +
			0.5 * stepfun(time.base, c(1, surv.base), right = TRUE )(t)
		}
	}
	return(out)
}


### READ DATA and SOME PROCESSING  #####################################################

### read data ###
train <- read.csv(path.train.data);
train$vital.status <- as.integer(train$vital.status == 'D');
test  <- read.csv(path.test.data);

### grouping variables ###
var.id         <- names(train)[grepl('Patient_id', names(train)) ];  # the `#` in patient id cannot be recognized by R
var.resps      <- c('resp.simple', 'Relapse', 'vital.status', 'Overall_Survival', 'Remission_Duration');
var.resp       <- c('Overall_Survival', 'vital.status');
var.other.resp <- setdiff(var.resps, var.resp);
var.clinic     <- setdiff(names(train)[1:41], c(var.id, var.resp, var.other.resp));
var.protein    <- names(train)[42 : ncol(train)];
# var.selected comes from the benchmark model
var.selected   <- c('Age.at.Dx', 'cyto.cat', 'Chemo.Simplest', 'HGB', 'ALBUMIN');

N.train <- nrow(train);
N.test <- nrow(test);

### filling missing values, by medians if continuous and by mode if discrete ###
for (i in 1:ncol(train) ) {
    if (!any(is.na(train[[i]]))) next;
    if (is.factor(train[[i]]))
        train[[i]][is.na(train[[i]])] <- names(sort(table(train[[i]]), decreasing = TRUE))[1];
    if (is.numeric(train[[i]]))
        train[[i]][is.na(train[[i]])] <- median(train[[i]], na.rm = TRUE)
    }

### recategorize `cyto.cat` ###
# 0. Reasons to recategorize:  
#   a.) too munch levels, which requres more model parameters
#   b.) very imbalancedly distributed. Some categories has only 1 or few cases. Parameter estimates on these categories are not convincing
#   c.) in one word, to gain power by smoothing/reducing parameters in parametric or semi-parametric models
#
# 1. from wikipedia and other papers on AML cytogeneric, roughly group by `risk`. But some categories do not appear on the wikipage/papers
# 2. two catergories in `test` dataset are not in `training` set. So assign them to a close categories.
# 3. Fit a Coxph model on this covariate only with elasticNet (alpha = 0.5) using cv.glmnet (package: glmnet). ElasticNet gives simmilar 
#   estiamtes to `closer variables` (catergorized into 6 catergories), baseline and cat1-5 below.
# 4. Use ANOVO to collapse some levels to the baseline level ('-5') and further reduce number of levels to 4, baseline and cat1, cat3, cat5.
#
# NOTE: this recategorization is somewhat ad-hoc, and more of a personal choice.

#train$cyto.cat0 <- factor(train$cyto.cat %in% c('-5', '11q23', 'IM', 'Misc', 'inv9', 't6;9', 't9,22'));
train$cyto.cat1 <- factor(train$cyto.cat %in% c('-7', '-5,-7', '-5,-7,+8', '-7,+8'));
#train$cyto.cat2 <- factor(train$cyto.cat %in% c('8'));
train$cyto.cat3 <- factor(train$cyto.cat %in% c('diploid'));
#train$cyto.cat4 <- factor(train$cyto.cat %in% c('21')); 
train$cyto.cat5 <- factor(train$cyto.cat %in% c('inv16', 't8;21'));

test$cyto.cat1 <- factor(test$cyto.cat %in% c('-7', '-5,-7', '-5,-7,+8', '-7,+8'));
test$cyto.cat3 <- factor(test$cyto.cat %in% c('diploid'));
test$cyto.cat5 <- factor(test$cyto.cat %in% c('inv16', 't8;21'));

# The `5 variables` in the benchmark model
var.selected <- c('Age.at.Dx', 'Chemo.Simplest', 'HGB', 'ALBUMIN', 'cyto.cat1', 'cyto.cat3', 'cyto.cat5');



### DEINE SOME FUNCTIONS FOR BAGGED COXPH MODEL ####################################################

cox.single <- function(formula, data, i.train) {
    train.data <- data[i.train, ];
    cox.f <- coxph(
        formula,
        data = train.data,
        method = 'breslow'
        );
    return(list(inbag = i.train, model = cox.f))
    }

cox.bagged <- function(formula, data, B = 500, error.skip = TRUE, error.verbose = TRUE, seed = NULL) {
	if (!is.null(seed)) set.seed(seed);
	i.trains <- replicate(
						  n = B,
						  expr = sample(1:nrow(data), size = nrow(data), replace = TRUE)
						  );
	bagged.model <- foreach(i = 1:B, .combine = c) %dopar% {
		tryCatch(
				 expr = {
					 i.train <- sample(1:nrow(data), size = nrow(data), replace = TRUE);
					 list(cox.single(formula, data, i.train = i.trains[, i]))
				 },
				 error = function(e) {
					 if (error.skip) {
						 if (error.verbose) {
							 message(sprintf('Model %d failed and skipped.', i));
						 }
						 NULL
					 } else { stop(e) }
				 }
				 )
	};
	bagged.model <- list(model = bagged.model, B = length(bagged.model), data = data);
	class(bagged.model) <- 'bag.cox';
	return(bagged.model);
}

predict.bag.cox <- function(obj, newdata, ps = seq(0.2, 0.5, 0.1), mean.lower = 0.2, mean.upper = 0.5) {
	if (missing(newdata)) {
		preds <- foreach(i = 1:obj$B) %dopar% {
			i.train <- obj$model[[i]]$inbag;
			train.data <- obj$data[i.train, ];
			i.oob <- setdiff(1:nrow(obj$data), i.train);
			oob.data <- obj$data[i.oob, ];

			cox.preds <- predictSurvival(
							p = ps,
						    test.link = predict(obj$model[[i]]$model, newdata = oob.data),
						    train.link = predict(obj$model[[i]]$model, newdata = train.data),
							train.time = train.data[, 'Overall_Survival'],
							train.status = train.data[, 'vital.status'],
							max.time = 600
							);

			colnames(cox.preds) <- as.character(ps);

			# average over mean.lower to mean.upper
			cox.ave <- rowMeans(cox.preds[, ps <= mean.upper & ps >= mean.lower]);
			cox.preds <- cbind(index = i.oob, cox.preds[, 1:length(ps)], '1' = cox.ave);
			#list(oob = i.oob, preds = cox.preds)
		};

		out <- foreach(p = c(ps, 1), .combine = cbind, .inorder = TRUE) %dopar% {
					  all.oob.pred <- Reduce(
									f = rbind,
									x = lapply(preds, FUN = function(x) x[, c('index', as.character(p))])
									);
					  tapply(all.oob.pred[, 2], INDEX = all.oob.pred[, 1], FUN = mean, na.rm = TRUE)
					  };
		colnames(out) <- as.character(c(ps, 1));
		out
	} else {
		preds <- foreach(i = 1:obj$B, .combine = '+') %dopar% {
			i.train <- obj$model[[i]]$inbag;
			train.data <- obj$data[i.train, ];

			cox.preds <- predictSurvival(
								p = ps,
								test.link = predict(obj$model[[i]]$model, newdata = newdata),
								train.link = predict(obj$model[[i]]$model, newdata = train.data),
								train.time = train.data[, 'Overall_Survival'],
								train.status = train.data[, 'vital.status'],
								max.time = 600
								);

			colnames(cox.preds) <- as.character(ps);

			# average over mean.lower to mean.upper
			cox.ave <- rowMeans(cox.preds[, ps <= mean.upper & ps >= mean.lower]);
			cox.preds <- cbind(cox.preds[, 1:length(ps)], '1' = cox.ave);
			#list(oob = i.oob, preds = cox.preds)
		} / obj$B;
		preds
	}
}


### BEGIN FITTING ##################################################################################
# Model: 
# h(t) = h_0(t) Z^alpha exp(beta*Z) = h_0(t) exp(beta*Z + alpha*log(Z))
# Reason to add `Z^alpha`: 
#   try to reduce biasness (main concern of bagging)
#   the potentially inflated variance can be reduced by bagging

message('Fitting model. Please wait ...');
bag.cox.f <- cox.bagged(
    formula = Surv(Overall_Survival, vital.status) ~ . +
            I(log(Age.at.Dx)) + I(log(HGB)) + I(log(ALBUMIN)),
    data = train[, c(var.resp, var.selected)],
    B = 500
    );

# chosen mean.lower and mean.upper is based on C-index and PCC (plot CI and PCC versus `ps`)
# a lower survival probability seems to give more accurate predictions compared to median survival times
# the final predictions are chosen to be the average over `mean.lower = 0.1` and `mean.upper = 0.3`

# out-of-bag(OOB) prediction on training
message('Predicting training dataset using out-of-bag sample ...');
bag.cox.oob <- predict(
    bag.cox.f, ps = seq(0.1, 0.3, 0.01),
    mean.lower = 0.1, mean.upper = 0.3
    );

message('Predicting testing dataset ...');
bag.cox.pred.on.test <- predict(
    bag.cox.f,
    newdata = test[, var.selected],
    ps = seq(0.1, 0.3, 0.01),
    mean.lower = 0.1, mean.upper = 0.3
    );

i.oob <- as.numeric(rownames(bag.cox.oob));

# out-of-bag performance estimation
# the `mean.lower` and `mean.upper` are chosen base on it.
bag.cox.pf <- apply(
        bag.cox.oob, 2, 
        function(x) get.pcc.ci(
                x, train[i.oob, 'Overall_Survival'], 
                train[i.oob, 'vital.status']
                )
        );

message(paste0(rep('-', 60), collapse = ''));
message(sprintf(
	'Estimated performance based on out-of-bag samples:\n\tPCC = %f\n\tCI  = %f',
	bag.cox.pf[1, ncol(bag.cox.pf)],
	bag.cox.pf[2, ncol(bag.cox.pf)]
	));

### confidence of prediction ###
# based on the "variance" of the survival time distribution, more precisely, the quntile differences 
confid.train <- abs(bag.cox.oob[, 1] - bag.cox.oob[, ncol(bag.cox.oob)-1]);
confid.train <- 0.2 + rank(-confid.train) / (2*length(confid.train)); # range from 0.2 - 0.7
confid.test <- abs(bag.cox.pred.on.test[, 1] - bag.cox.pred.on.test[, ncol(bag.cox.pred.on.test)-1]);
confid.test <- 0.2 + rank(-confid.test) / (2*length(confid.test));  # range from 0.2 - 0.7

### predictions for output ###
# used the average over `mean.lower` and `mean.upper` as predictions, which are saved in the last column
pred.train <- bag.cox.oob[, ncol(bag.cox.oob)];
pred.test <- bag.cox.pred.on.test[, ncol(bag.cox.pred.on.test)];

# added noises to the predictions, due to the definition of C-index on ties for this challenge
if (any(pred.train == 600)) pred.train[pred.train == 600] <- 600 - rexp(sum(pred.train == 600), 10);
if (any(pred.test  == 600)) pred.test[pred.test == 600] <- 600 - rexp(sum(pred.test == 600), 10);

outfile.train <- data.frame(
                       '#Patient_id' = train[, var.id], 
                       'Overall_Survival' = pred.train,
                       'Confidence' = round(confid.train, 4),
					   stringsAsFactors = FALSE,
					   check.names = FALSE
                       );
outfile.test <- data.frame(
                       '#Patient_id' = test[, var.id], 
                       'Overall_Survival' = pred.test,
                       'Confidence' = round(confid.test, 4),
					   stringsAsFactors = FALSE,
					   check.names = FALSE
                       );

write.csv(
			x = outfile.train, 
			file = file.path(path.output, 'Chipmunks-AML_subchallenge3_submission_train.csv'), 
			quote = FALSE, 
			row.names = FALSE
			);
write.csv(
			x = outfile.test , 
			file = file.path(path.output, 'Chipmunks-AML_subchallenge3_submission_test.csv' ), 
			quote = FALSE, 
			row.names = FALSE
			);

message(sprintf('Predctions on training dataset are saved as\n\t%s/Chipmunks-AML_subchallenge3_submission_train.csv', path.output));
message(sprintf('Predctions on testing dataset are saved as\n\t%s/Chipmunks-AML_subchallenge3_submission_test.csv', path.output));
message(paste0(rep('-', 60), collapse = ''));
message('DONE!!! CHEERS!!!\n');
